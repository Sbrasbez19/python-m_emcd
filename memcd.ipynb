{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f617a598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from typing import List, Set, Tuple, Union\n",
    "from scipy.sparse import lil_matrix\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import math \n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af466922",
   "metadata": {},
   "source": [
    "Please note that this is a very raw version of the algorithm: the code is now organized as a number of functions that should be organized more coherently in an actual class or integrated in an existing library. It works, though.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6134c23",
   "metadata": {},
   "source": [
    "<H2> UTILS </H2\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "369149dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_from_nodes_list(nodes: Set, edge_list: np.ndarray, create_using = nx.DiGraph) -> nx.Graph:\n",
    "    if create_using == nx.Graph:\n",
    "        G = nx.Graph()\n",
    "    elif create_using == nx.DiGraph:\n",
    "        G = nx.DiGraph()\n",
    "    G.add_nodes_from(nodes)\n",
    "    G.add_weighted_edges_from(edge_list)\n",
    "    return G\n",
    "\n",
    "#Gs is the list of graphs (layers) of our multiplex network.\n",
    "#layer_labels is the list of labels associated to each layer. so layer_labels[0] will be the label of the edges in Gs[0].\n",
    "def create_multiplex_from_graphs(Gs: List[nx.Graph], layer_labels: List[str], is_directed: bool = True, has_attr: bool = True) -> nx.MultiGraph:\n",
    "    #assuming we are dealing with multiplex networks -> for every G in Gs, <V> is the same\n",
    "    multiplex_nodes = Gs[0].nodes.items()\n",
    "    if is_directed:\n",
    "        mp = nx.MultiDiGraph()\n",
    "    else:\n",
    "        mp = nx.MultiGraph()\n",
    "    mp.add_nodes_from(multiplex_nodes)\n",
    "    \n",
    "    for i, G in enumerate(Gs):\n",
    "        mp_edges = get_edges_for_multiplex_graph(G, layer_labels[i], has_attr)\n",
    "        mp.add_edges_from(mp_edges)\n",
    "    \n",
    "    layer_mapping = {i: label for i, label in enumerate(layer_labels)}\n",
    "    mp.graph['layers'] = layer_mapping\n",
    "    return mp\n",
    "\n",
    "def get_edges_for_multiplex_graph(G: nx.Graph, key: None, has_attr: bool = True) -> List[Tuple]:\n",
    "    edges = nx.to_edgelist(G)\n",
    "    mp_edges = []\n",
    "    for edge in edges:\n",
    "        if has_attr and key:\n",
    "            mp_edges.append(tuple_insert(edge, 2, key))\n",
    "        elif key and has_attr == False:\n",
    "            mp_edges.append(edge + (key,))\n",
    "        else:\n",
    "            mp_edges.append(edge)\n",
    "    return mp_edges\n",
    "\n",
    "def tuple_insert(tup,pos,ele):\n",
    "    tup = tup[:pos]+(ele,)+tup[pos:]\n",
    "    return tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b8a5028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXAMPLE AND TESTING\n",
    "# ============================================================================\n",
    "\n",
    "def create_tagarelli_network(return_as_list: bool = True) -> Union[nx.Graph, List[List]]:\n",
    "\n",
    "    nodelist = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
    "\n",
    "    clustering = [\n",
    "        [['1', '2', '3'], ['4', '5', '6'], ['7', '8', '9', '10']],\n",
    "        [['1', '2', '3'], ['4', '6', '7', '9']],\n",
    "        [['2', '4', '5', '6'], ['7', '8', '9']]\n",
    "    ]\n",
    "\n",
    "    G = nx.MultiGraph()\n",
    "\n",
    "\n",
    "    # Define layers\n",
    "    layers = { 0: 'L1',\n",
    "              1: 'L2',\n",
    "              2: 'L3'\n",
    "    }\n",
    "    G.graph['layers'] = layers\n",
    "\n",
    "    if return_as_list: \n",
    "        G1 = nx.Graph()\n",
    "        G2 = nx.Graph()\n",
    "        G3 = nx.Graph()\n",
    "\n",
    "        G1.add_nodes_from(nodelist)\n",
    "        G2.add_nodes_from(nodelist)\n",
    "        G3.add_nodes_from(nodelist)\n",
    "\n",
    "        #LAYER 1\n",
    "        G1.add_edge('1', '2', weight = 1.0)\n",
    "        G1.add_edge('2', '3', weight = 1.0)\n",
    "        G1.add_edge('2', '6', weight = 1.0)\n",
    "        G1.add_edge('4', '5', weight = 1.0)\n",
    "        G1.add_edge('4', '6', weight = 1.0)\n",
    "        G1.add_edge('5', '6', weight = 1.0)\n",
    "        G1.add_edge('5', '7', weight = 1.0)\n",
    "        G1.add_edge('6', '9', weight = 1.0)\n",
    "        G1.add_edge('7', '8', weight = 1.0)\n",
    "        G1.add_edge('7', '9', weight = 1.0)\n",
    "        G1.add_edge('8', '9', weight = 1.0)\n",
    "        G1.add_edge('8', '10', weight = 1.0)\n",
    "        G1.add_edge('9', '10', weight = 1.0)\n",
    "\n",
    "        #LAYER 2\n",
    "        G2.add_edge('1', '2', weight = 1.0)\n",
    "        G2.add_edge('1', '3', weight = 1.0)\n",
    "        G2.add_edge('2', '3', weight = 1.0)\n",
    "        G2.add_edge('3', '4', weight = 1.0)\n",
    "        G2.add_edge('4', '6', weight = 1.0)\n",
    "        G2.add_edge('4', '9', weight = 1.0)\n",
    "        G2.add_edge('6', '7', weight = 1.0)\n",
    "        G2.add_edge('6', '9', weight = 1.0)\n",
    "        G2.add_edge('7', '9', weight = 1.0)\n",
    "\n",
    "        #LAYER 3\n",
    "        G3.add_edge('2', '4', weight = 1.0)\n",
    "        G3.add_edge('2', '6', weight = 1.0)\n",
    "        G3.add_edge('4', '5', weight = 1.0)\n",
    "        G3.add_edge('4', '6', weight = 1.0)\n",
    "        G3.add_edge('5', '6', weight = 1.0)\n",
    "        G3.add_edge('5', '7', weight = 1.0)\n",
    "        G3.add_edge('7', '8', weight = 1.0)\n",
    "        G3.add_edge('7', '9', weight = 1.0)\n",
    "        G3.add_edge('8', '9', weight = 1.0)\n",
    "\n",
    "        return [G1, G2, G3], clustering\n",
    "    else:\n",
    "        raise ValueError('Not implemented yet, return as list')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2efd5c",
   "metadata": {},
   "source": [
    "<H2> M-EMCD IMPLEMENTATION </H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8821732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================ #\n",
    "# COMMUNITIES MANIPULATION\n",
    "# ================================================================ #\n",
    "\n",
    "def get_nodes_in_communities(communities: List[int], G: nx.Graph) -> List[str]:\n",
    "    nodes = np.array(list(G.nodes()))\n",
    "    #print(nodes)\n",
    "    n_clusters = np.unique(communities)\n",
    "    communities_by_nodes = []\n",
    "    for i in n_clusters:\n",
    "        mask = np.array([True if com == i else False for com in communities], dtype = bool)\n",
    "        \n",
    "        nodes_subset = nodes[mask]\n",
    "        #print(nodes_subset)\n",
    "        communities_by_nodes.append(nodes_subset)\n",
    "    return communities_by_nodes\n",
    "\n",
    "def get_intercomm_edges_as_list(com: dict) -> List:\n",
    "    com_edges_list = []\n",
    "    for cj, intercomm_edges_ci_cj in com.items():\n",
    "        for layer in intercomm_edges_ci_cj.values():\n",
    "            if len(layer) > 0:\n",
    "                com_edges_list.extend(layer)\n",
    "    return com_edges_list\n",
    "\n",
    "def create_consensus_structure(G: nx.MultiGraph, intracomm_edges: dict, intercomm_edges: dict) -> nx.MultiGraph:\n",
    "    if G.is_directed():\n",
    "        consensus_structure = nx.MultiDiGraph()\n",
    "    else:\n",
    "        consensus_structure = nx.MultiGraph()\n",
    "    communities = []\n",
    "    consensus_nodes = list(G.nodes(data = False))\n",
    "    consensus_structure.add_nodes_from(consensus_nodes)\n",
    "    #add intracommunity edges and create internal community structure\n",
    "    for community in intracomm_edges.values():\n",
    "        comm_edges = []\n",
    "        for layer in community:\n",
    "            if len(community[layer]) > 0:\n",
    "                consensus_structure.add_edges_from(community[layer])\n",
    "                comm_edges.extend([(e[0], e[1], e[2]) for e in community[layer]])\n",
    "        communities.append(consensus_structure.edge_subgraph(comm_edges))\n",
    "    #add intercommunity edges to consensus structure\n",
    "    for community in intercomm_edges.keys():\n",
    "        intercomm_edges_list = get_intercomm_edges_as_list(intercomm_edges[community])\n",
    "        consensus_structure.add_edges_from(intercomm_edges_list)\n",
    "\n",
    "    return consensus_structure, communities    \n",
    "        \n",
    "\n",
    "# ================================================================ #\n",
    "# EDGE MANIPULATION FUNCTIONS\n",
    "# ================================================================ #\n",
    "\n",
    "def get_edges_between_u_v(G: nx.MultiDiGraph, u: str, v: str, return_data: bool = False) -> List:\n",
    "    edges = G.edges(u, data = return_data, keys = True)\n",
    "    uv_edges = []\n",
    "    for edge in edges:\n",
    "        if edge[1] == v:\n",
    "            uv_edges.append(edge)\n",
    "    return uv_edges\n",
    "\n",
    "def get_edges_between_u_v_by_layer(G: nx.MultiGraph, u: str, v: str, layers: List[str] = None, return_data: bool = False) -> dict:\n",
    "    edges = G.edges(u, data = return_data, keys = True)\n",
    "    by_layer = {k: [] for k in G.graph['layers'].values()}\n",
    "    for edge in edges:\n",
    "        if edge[1] == v:\n",
    "            if layers:\n",
    "                if edge[2] in layers:\n",
    "                    by_layer[edge[2]].append(edge)\n",
    "            else:\n",
    "                by_layer[edge[2]].append(edge)\n",
    "    return by_layer\n",
    "\n",
    "def get_edges_in_layer_for_node(node, G: nx.MultiDiGraph, layer: str, return_data: bool = True) -> List:\n",
    "    edges_for_node_in_layer = [edge for edge in G.edges(node, keys = True, data = return_data) if edge[2] == layer]\n",
    "    return edges_for_node_in_layer\n",
    "\n",
    "def get_nodes_induced_intercommunity_edges(G: nx.MultiDiGraph, com_1: nx.MultiDiGraph, com_2: nx.MultiDiGraph, layer: str) -> List:\n",
    "    edges_between = []\n",
    "    for u in com_1.nodes(data = False):\n",
    "        for v in com_2.nodes(data = False):\n",
    "            edges_uv = get_edges_between_u_v(G, u, v, True)\n",
    "            if edges_uv:\n",
    "                edges_between.extend([edge for edge in edges_uv if edge[2] == layer])\n",
    "    return edges_between\n",
    "\n",
    "def get_intracommunity_edges_ccemcd(G: nx.MultiGraph, mij: dict, community: nx.MultiGraph):\n",
    "    community_nodes = list(community.nodes(data = False))\n",
    "    intracomm_edges = {layer: [] for layer in G.graph['layers'].values()}\n",
    "    #intracomm_edges = []\n",
    "    for node in community_nodes:\n",
    "        if mij[node]:\n",
    "            for k in mij[node].keys():\n",
    "                #print(f'checking edges for {node} - {k}')\n",
    "                uv_edges = get_edges_between_u_v_by_layer(G, node, k, None, True)\n",
    "                for layer in G.graph['layers'].values():\n",
    "                    intracomm_edges[layer].extend(uv_edges[layer])\n",
    "                #print(uv_edges)\n",
    "    return intracomm_edges\n",
    "\n",
    "def get_intracommunity_edges_matrix_ccemcd(G: nx.MultiGraph, communities: List[nx.MultiGraph], mij: dict) -> dict:\n",
    "    intracomm_edges_dict = {i: {layer: [] for layer in G.graph['layers'].values()} for i in range(len(communities))}\n",
    "    for i, com in enumerate(communities):\n",
    "        intracomm_edges = get_intracommunity_edges_ccemcd(G, mij, com)\n",
    "        if len(intracomm_edges) > 0:\n",
    "            for layer in G.graph['layers'].values():\n",
    "                intracomm_edges_dict[i][layer].extend(intracomm_edges[layer])\n",
    "            #intracomm_edges_dict[i].extend(get_intracommunity_edges_ccemcd(G, mij, com))\n",
    "    return intracomm_edges_dict\n",
    "\n",
    "def get_intercommunity_edges_ccemcd(G: nx.MultiGraph, inverse_mij: dict, communities: List[nx.MultiGraph]) -> dict:\n",
    "    intercomm_edges = {c:\n",
    "                        {k:\n",
    "                          {layer: [] for layer in G.graph['layers'].values()} \n",
    "                          for k, _ in enumerate(communities)}\n",
    "                        for c, _ in enumerate(communities)}\n",
    "    if len(communities) <= 1:\n",
    "        return intercomm_edges\n",
    "    #intercomm_edges = {c: {} for c, _ in enumerate(communities)}\n",
    "    for key_i, value in inverse_mij.items():\n",
    "        c1_idx  = get_community_index_for_node(key_i, communities)\n",
    "        # print(f'i : {key_i}')\n",
    "        for key_j in value.keys():\n",
    "            # print(f'      j : {key_j}')\n",
    "            c2_idx = get_community_index_for_node(key_j, communities)\n",
    "            #print(c2_idx)\n",
    "            to_select = [layer for layer, intercoms in value[key_j].items() if len(intercoms) > 0]\n",
    "            c1_c2_edges = get_edges_between_u_v_by_layer(G, key_i, key_j, to_select, True)\n",
    "            # print(f'             edges between i, j: {c1_c2_edges}')\n",
    "            # print(intercomm_edges)\n",
    "            for layer in to_select:\n",
    "                intercomm_edges[c1_idx][c2_idx][layer].extend(c1_c2_edges[layer])                               \n",
    "    return intercomm_edges\n",
    "\n",
    "def get_community_index_for_node(node: str, communities: List[nx.MultiGraph]) -> int:\n",
    "    for i, com in enumerate(communities):\n",
    "        community_nodes = list(com.nodes(data = False))\n",
    "        if node in community_nodes:\n",
    "            return i\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_edges_to_community(com: nx.MultiDiGraph, edges) -> nx.MultiDiGraph:\n",
    "    c_updated = deepcopy(com)\n",
    "    c_updated.add_edges_from(edges)\n",
    "    return c_updated\n",
    "\n",
    "def compute_edge_difference_set(e1, e2):\n",
    "    return [e for e in e1 if e not in e2]\n",
    "\n",
    "# ================================================================ #\n",
    "# CO-ASSOCIATION MATRIX CONSTRUCTION \n",
    "# ================================================================ #\n",
    "\n",
    "def compute_mij(node_i: str, node_j: str, G: nx.MultiDiGraph, clustering: List[List], n_layers: int, linkage_constraint: bool = False) -> float:\n",
    "    #print(node_i)\n",
    "    mij = {layer: [] for layer in G.graph['layers'].values()}\n",
    "    inverse_mij = {layer: [] for layer in G.graph['layers'].values()}\n",
    "    #inverse_mij = []\n",
    "    #mij = []\n",
    "    for i in range(n_layers):\n",
    "        current_layer = G.graph['layers'][i]\n",
    "        for j, com in enumerate(clustering[i]):\n",
    "            #if both are not in the current community we cannot say anything, \n",
    "            #maybe they share the next one. But if only one of node_i or node_j are in the community,\n",
    "            #then surely they won't share the community (they are disjoint), yet they may potentially be linked in this layer\n",
    "            share_comm = (node_i in com) and (node_j in com)\n",
    "            one_of_two_in_comm =  node_i in com and (not node_j in com) or node_j in com and (not node_i in com)\n",
    "            if (not share_comm) and (one_of_two_in_comm):\n",
    "                if linkage_constraint:\n",
    "                    if G.has_edge(node_i, node_j, key = current_layer):\n",
    "                        #inverse_mij.append(i)\n",
    "                        inverse_mij[current_layer].append(j)\n",
    "                #inverse_mij is not defined in case we do not have the linkage constraint since mij contains all the edges connecting two nodes\n",
    "            elif share_comm:\n",
    "                if linkage_constraint:\n",
    "                    if G.has_edge(node_i, node_j, key = current_layer):\n",
    "                        #mij.append((i, j))\n",
    "                        mij[current_layer].append(j)\n",
    "                else:\n",
    "                    #mij.append((i,j))\n",
    "                    mij[current_layer].append(j)\n",
    "        \n",
    "    return mij, inverse_mij\n",
    "\n",
    "\n",
    "#THE VERSION TO USE, OPTIMIZED FOR TIME AND SPACE \n",
    "def compute_coass_sparse_matrix(G: nx.Graph, clustering: List[List[str]], as_distance_matrix: bool = True, linkage_constraint: bool = False, theta: float =  None):\n",
    "    nodes = list(G.nodes())\n",
    "    n_nodes = len(nodes)\n",
    "    n_layers = len(clustering)\n",
    "    #use sparse matrices for efficiency\n",
    "    coass_matrix = lil_matrix((n_nodes, n_nodes), dtype= np.float32)\n",
    "    #mij contains, for every pair of nodes, a reference to the layers in which i,j share the same community and are also connected by an edge\n",
    "    mij = {str(k): {} for k in nodes}\n",
    "    #inverse mij contains, for every pair of nodes, a reference to the layers in which i,j do not share the same community but are connected by an edge\n",
    "    inverse_mij = {str(k): {} for k in nodes}\n",
    "    #flags for updates\n",
    "    added_mij = False\n",
    "    added_inverse_mij = False\n",
    "    #start the loop\n",
    "    for i, node_i in enumerate(nodes):\n",
    "        for j, node_j in enumerate(nodes):\n",
    "            #reset flags\n",
    "            added_mij = False\n",
    "            added_inverse_mij = False\n",
    "            if node_i != node_j:\n",
    "                #compute mij and inverse_mij to keep track of intracommunity and intercommunity edges in the clustering steps\n",
    "                mij_tmp, inverse_mij_tmp = compute_mij(node_i, node_j, G, clustering, n_layers, linkage_constraint)\n",
    "                len_mij = sum([len(mij_tmp[layer]) for layer in list(mij_tmp.keys())])\n",
    "                len_inverse_mij  = sum([len(inverse_mij_tmp[layer]) for layer in list(mij_tmp.keys())])\n",
    "                #if len(mij_tmp) > 0:\n",
    "                if len_mij > 0:\n",
    "                    #add only if we have mij, for space reasong\n",
    "                    #consider the linkage constraint threshold theta for cc-emcd\n",
    "                    if theta:\n",
    "                        #if(len(mij_tmp)/n_layers) >= theta:\n",
    "                        if len_mij/n_layers > theta:\n",
    "                            mij[node_i][node_j] = mij_tmp\n",
    "                            added_mij = True\n",
    "                        else:\n",
    "                            #if we have a threshold and we do not surpass it, empty mij so that coass[i, j] = 0 (or 1 if as distance)\n",
    "                            #mij_tmp = []\n",
    "                            len_mij = 0\n",
    "                    else:\n",
    "                        mij[node_i][node_j] = mij_tmp\n",
    "                        added_mij = True\n",
    "                    if as_distance_matrix:\n",
    "                        #coass_matrix[i, j] =  1 - (len(mij_tmp) / n_layers)\n",
    "                        coass_matrix[i, j] =  1 - (len_mij / n_layers)\n",
    "                    else:\n",
    "                        #coass_matrix[i, j] =  len(mij_tmp) / n_layers\n",
    "                        coass_matrix[i, j] =  1 - (len_mij / n_layers)\n",
    "                else:\n",
    "                #if mij is 0 then the distance is 1, if we do not want the distance matrix we can skip\n",
    "                    if as_distance_matrix:\n",
    "                        coass_matrix[i, j] = 1\n",
    "                #add if we have links when we do not share communities and update flag\n",
    "                #if len(inverse_mij_tmp) > 0:\n",
    "                if len_inverse_mij > 0:\n",
    "                    inverse_mij[node_i][node_j] = inverse_mij_tmp\n",
    "                    added_inverse_mij = True\n",
    "               #symmetry in case the graph is undirected\n",
    "                if not G.is_directed():\n",
    "                    if added_mij:\n",
    "                        mij[node_j][node_i] = mij[node_i][node_j]\n",
    "                        coass_matrix[j, i] = coass_matrix[i, j]\n",
    "                    if added_inverse_mij:\n",
    "                        inverse_mij[node_i][node_j] = {k: list(set(v)) for k, v in inverse_mij[node_i][node_j].items()}\n",
    "    return coass_matrix, mij, inverse_mij\n",
    "\n",
    "# ================================================================ #\n",
    "# DEGREE COMPUTATION FUNCTIONS\n",
    "# ================================================================ #\n",
    "\n",
    "#compute the internal degree of a community \n",
    "#assuming the community only has internal edges\n",
    "def get_community_internal_layer_degree(com: nx.MultiDiGraph, layer: str) -> float:\n",
    "    #layer_edges = get_edges_in_layer(com, layer)\n",
    "    layer_internal_degree = 0.0\n",
    "    for node in com.nodes():\n",
    "        neighbors = com.neighbors(node)\n",
    "        for neighbor in neighbors:\n",
    "            if neighbor in com.nodes() and com.has_edge(node, neighbor, layer):\n",
    "                layer_internal_degree += com[node][neighbor][layer]['weight']\n",
    "    return layer_internal_degree\n",
    "\n",
    "#compute the layer degree of a graph\n",
    "def get_layer_degree(G: nx.MultiDiGraph, layer: str) -> float:\n",
    "    layer_edges = get_edges_in_layer(G, layer, False)\n",
    "    print(layer_edges)\n",
    "    layer_subgraph = G.edge_subgraph(layer_edges)\n",
    "    return sum([layer_subgraph.degree(node, weight = 'weight') for node in layer_subgraph])\n",
    "\n",
    "#given a graph com and a layer, returns the edges of com in the layer specified by the layer param.\n",
    "# get_data specifies whether the edges data also have to be returned or not\n",
    "def get_edges_in_layer(com: nx.MultiDiGraph, layer: str, return_data: bool = True) -> list:\n",
    "    edges_in_layer = [edge for edge in com.edges(keys = True, data = return_data) if edge[2] == layer]\n",
    "    return edges_in_layer\n",
    "\n",
    "def get_node_layer_degree(node, G: nx.MultiGraph, layer: str, weight: str = 'weight') -> float:\n",
    "    edges_for_node_in_layer = get_edges_in_layer_for_node(node, G, layer, True)\n",
    "    degree = np.sum([e[3][weight] for e in edges_for_node_in_layer])\n",
    "    return degree\n",
    "\n",
    "def D_sq_l_c_new(d_lc_dict: dict) -> float:\n",
    "    coms_degrees = []\n",
    "    for com in d_lc_dict.keys():\n",
    "        com_degree = 0\n",
    "        for l_deg in d_lc_dict[com].values():\n",
    "            com_degree += math.pow(l_deg, 2)\n",
    "        coms_degrees.append(com_degree)\n",
    "    return np.sum(coms_degrees)\n",
    "\n",
    "#compute a dict such that dict[i][l] = degree for community i at layer l\n",
    "def compute_D_l_c_dict(consensus: nx.MultiDiGraph, communities: List[nx.MultiDiGraph], layers: list[str], weight: str = 'weight') -> dict:\n",
    "    degree_dict = {i: {l: 0 for l in layers} for i, _ in enumerate(communities)}\n",
    "    for i, com in enumerate(communities):\n",
    "        degree_dict[i] = compute_community_D_l_c(consensus, com, layers, weight)\n",
    "    return degree_dict\n",
    "\n",
    "def compute_community_D_l_c(consensus, community, layers: str, weight: str = 'weight') -> float:\n",
    "    layers_degrees_dict = {l: 0 for l in layers}\n",
    "    com_nodes = list(community.nodes(data = False))\n",
    "    for layer in layers:\n",
    "        layer_degree = 0\n",
    "        for node in com_nodes:\n",
    "            node_degree_in_layer = get_node_layer_degree(node, consensus, layer, weight)\n",
    "            layer_degree += node_degree_in_layer\n",
    "        layers_degrees_dict[layer] = layer_degree\n",
    "    return layers_degrees_dict\n",
    "\n",
    "def D_VL_new(G:nx.MultiGraph) -> float:\n",
    "    nodes_degree = dict(G.degree())\n",
    "    whole_degree = np.sum([deg for deg in nodes_degree.values()])\n",
    "    return whole_degree\n",
    "\n",
    "#we are keeping track of both the consensus structure (graph made of communities with internal and external edges) \n",
    "#and separated communities(communities with only the internal edges)\n",
    "def D_int_lc_new(coms: List[nx.MultiGraph]) -> float:\n",
    "    coms_degrees = []\n",
    "    #compute internal degree for each community\n",
    "    for com in coms:\n",
    "        com_degree = dict(com.degree())\n",
    "        coms_degrees.append(np.sum([deg for deg in com_degree.values()]))\n",
    "    return np.sum(coms_degrees)\n",
    "\n",
    "\n",
    "\n",
    "# ================================================================ #\n",
    "# MODULARITY UPDATE FUNCTIONS\n",
    "# ================================================================ #\n",
    "\n",
    "def modularity(d_vl: float, d_int_lc: float, d_sq_l_c: float) -> float:\n",
    "    if d_vl == 0:\n",
    "        return 0.0\n",
    "    return (1/d_vl * d_int_lc) - (1/math.pow(d_vl, 2) * d_sq_l_c)\n",
    "\n",
    "def modularity_within_update(d_vl: float, d_int_lc: float, d_sq_l_c: float, d_li_Cj: float, new_edges: List, is_weighted: bool = True) -> float:\n",
    "    \"\"\"\n",
    "    Modularity update for adding edges within communities (Equation 5).\n",
    "    \"\"\"\n",
    "    if is_weighted:\n",
    "        n_new_edges = sum([edge[3]['weight'] for edge in new_edges])\n",
    "    else:\n",
    "        n_new_edges = len(new_edges)\n",
    "\n",
    "    denominator = d_vl + 2*n_new_edges\n",
    "    if denominator == 0:\n",
    "        return 0.0\n",
    "    return ((d_int_lc + 2*n_new_edges) / (denominator)) - ((d_sq_l_c + 4 * n_new_edges * (n_new_edges + d_li_Cj))/math.pow(denominator, 2))\n",
    "\n",
    "def modularity_between_update(d_vl: float, d_int_lc: float, d_sq_l_c: float, d_li_Cj: float,d_li_Ch: float,\n",
    "                               new_edges_between: List, is_weighted: bool = True, weight: str = 'weight' ) -> float:\n",
    "    \"\"\"\n",
    "    Modularity update for adding edges between communities (Equation 7).\n",
    "    \"\"\"\n",
    "    if is_weighted:\n",
    "        #n_new_edges_between = [sum([edge[3]['weight'] for edge in edges]) for edges in new_edges_between]\n",
    "        n_new_edges_between = [edge[3][weight] for edge in new_edges_between]\n",
    "    else:\n",
    "        n_new_edges_between = [1 for edge in new_edges_between]\n",
    "\n",
    "    ne = sum(n_new_edges_between)\n",
    "    denominator = d_vl + 2*ne\n",
    "    #sq_sum_of_nek = sum([math.pow(nek, 2) for nek in n_new_edges_between])\n",
    "    sq_ne = math.pow(ne, 2)\n",
    "    weighted_degree = ne * (d_li_Cj + d_li_Ch)\n",
    "    \n",
    "    first_term = d_int_lc / denominator\n",
    "    second_term = (d_sq_l_c + 2*sq_ne + 2*weighted_degree)/math.pow(denominator, 2)\n",
    "    return ('a', first_term - second_term)\n",
    "\n",
    "def modularity_between_update_remove(d_vl: float, d_int_lc: float, d_sq_l_c: float,\n",
    "                                    d_li_Cj: float, d_li_Ch: float,\n",
    "                                    edges_to_remove: List,\n",
    "                                    is_weighted: bool = True, weight: str = 'weight') -> float:\n",
    "    \"\"\"\n",
    "    Modularity update for removing edges between communities (Equation 9 of the paper).\n",
    "    \"\"\"\n",
    "    # if len(edges_to_remove) == 0:\n",
    "    #     return ('r', d_int_lc / d_vl - d_sq_l_c / (d_vl ** 2))\n",
    "    if is_weighted:\n",
    "        #n_edges_to_remove = [sum([edge[3]['weight'] for edge in edges]) for edges in edges_to_remove]\n",
    "        n_edges_to_remove = [edge[3][weight] for edge in edges_to_remove]\n",
    "    else:\n",
    "        n_edges_to_remove = [1 for edge in edges_to_remove]\n",
    "\n",
    "    ne = sum(n_edges_to_remove)\n",
    "    denominator = d_vl - 2*ne\n",
    "    #sq_sum_of_nek = sum([math.pow(nek, 2) for nek in n_edges_to_remove])\n",
    "    sq_ne = math.pow(ne, 2)\n",
    "    weighted_degree = 2 * ne * (d_li_Cj + d_li_Ch)\n",
    "    #weighted_degree_of_neighbors = 2* sum([nek*d_li_ck for nek, d_li_ck in zip(n_edges_to_remove, d_li_Cs)])\n",
    "    first_term = d_int_lc / denominator\n",
    "    #second_term = (d_sq_l_c + math.pow(ne, 2) + sq_sum_of_nek - 2*ne*d_li_Cj - weighted_degree_of_neighbors)/math.pow(denominator, 2)\n",
    "    second_term = (d_sq_l_c + 2*sq_ne - weighted_degree)/ math.pow(denominator, 2)\n",
    "\n",
    "    return ('r', first_term - second_term)\n",
    "\n",
    "def modularity_between_update_both(d_vl: float, d_int_lc: float,\n",
    "                                   d_li_Cj: float, d_li_Ch: float, j: int,\n",
    "                                   cj: nx.MultiDiGraph, consensus: nx.MultiDiGraph, d_lc_dict: dict,\n",
    "                                   layers: List[str], current_layer: str,\n",
    "                                   edges_to_remove: List,\n",
    "                                   edges_to_add: List,\n",
    "                                   is_weighted: bool = False, \n",
    "                                   weight: str = 'weight') -> float:\n",
    "    \n",
    "    \"\"\"\n",
    "    Modularity update for both removing and adding edges between communities (chained).\n",
    "    \n",
    "    This chains two operations:\n",
    "    1. First remove current inter-community edges\n",
    "    2. Then add new inter-community edges\n",
    "    \n",
    "    Args:\n",
    "        d_vl: Total degree of multilayer graph\n",
    "        d_int_lc: Cumulative internal degree\n",
    "        d_sq_l_c: Cumulative squared degree\n",
    "        d_li_Cj: Degree of community Cj in layer Li\n",
    "        d_li_Ch: Degree of community Ch in layer Li\n",
    "        edges_to_remove: Edges to remove\n",
    "        edges_to_add: Edges to add\n",
    "        G: Multilayer graph\n",
    "        is_weighted: Whether edges have weights\n",
    "    \n",
    "    Returns:\n",
    "        Updated modularity after both operations\n",
    "    \"\"\"\n",
    "    consensus_copy = consensus.copy()\n",
    "    d_lc_dict_copy = d_lc_dict.copy()\n",
    "    consensus.add_edges_from(edges_to_add)\n",
    "    cj_dict_l_c = compute_community_D_l_c(consensus_copy, cj, layers, weight)\n",
    "    d_lc_dict_copy[j] = cj_dict_l_c\n",
    "    d_sq_l_c_plus = D_sq_l_c_new(d_lc_dict_copy)\n",
    "    modularity_plus_minus = modularity_between_update_remove(d_vl, d_int_lc, d_sq_l_c_plus, cj_dict_l_c[current_layer], d_li_Ch, edges_to_remove,\n",
    "                                                             is_weighted, weight)\n",
    "    return ('b', modularity_plus_minus[1])\n",
    "    \n",
    "# ================================================================ #\n",
    "# UPDATE FUNCTIONS\n",
    "# ================================================================ #\n",
    "\n",
    "def update_community(G: nx.MultiDiGraph, current_Q: float, cj: nx.MultiDiGraph, layer: str, d_vl: float, d_int_lc: float, d_sq_l_c: float, d_li_Cj: float) ->Union[nx.MultiDiGraph, float, List]:\n",
    "    #compute edges to add\n",
    "    cj_nodes_subgraph = G.subgraph(cj.nodes(data = False))\n",
    "    #available_edges = get_edges_in_layer(cj_nodes_subgraph, layer)\n",
    "    new_edges = compute_edge_difference_set(get_edges_in_layer(cj_nodes_subgraph, layer, True), get_edges_in_layer(cj, layer, True))\n",
    "    # print(f'available edges: {get_edges_in_layer(cj_nodes_subgraph, layer, True)}')\n",
    "    # print(f'edges already in community: {get_edges_in_layer(cj, layer, True)}')\n",
    "    # print(f'new edges to be added: {new_edges}')\n",
    "    #if there are no new edges we can return the current cj and current modularity\n",
    "    if len(new_edges) == 0:\n",
    "        return cj, current_Q, []\n",
    "    #else we add the edges to the community and compute the update\n",
    "    #cj_prime = deepcopy(cj)\n",
    "\n",
    "    cj_prime = cj.copy()\n",
    "    #cj_prime.add_edges_from(new_edges)\n",
    "    modularity_update = modularity_within_update(d_vl, d_int_lc, d_sq_l_c, d_li_Cj, new_edges, is_weighted = True)\n",
    "    return cj_prime, modularity_update, new_edges\n",
    "\n",
    "def update_community_structure(G: nx.MultiDiGraph, consensus: nx.MultiDiGraph, cj: nx.MultiDiGraph, ch:nx.MultiDiGraph,\n",
    "                                h: int, j: int, cj_neighbors: dict, layers: List[str], layer: str,\n",
    "                                d_vl: float, d_int_lc: float, d_sq_l_c: float, d_li_Cj: float, d_li_Ch: float, d_lc_dict: dict,\n",
    "                                is_weighted: bool = True, weight: str = 'weight'):\n",
    "    #get the neighbors between cj and ch at layers l\n",
    "    consensus_edges_between_cj_ch_for_l = cj_neighbors[h][layer]\n",
    "    #get the edges that are in the original graph but not in our consensus structure\n",
    "    edges_in_graph_between_cj_ch = get_nodes_induced_intercommunity_edges(G, cj, ch, layer)\n",
    "    e_prime = compute_edge_difference_set(edges_in_graph_between_cj_ch, consensus_edges_between_cj_ch_for_l)\n",
    "    #compute the removal update in modularity\n",
    "    removal_modularity_update = modularity_between_update_remove(d_vl, d_int_lc, d_sq_l_c, d_li_Cj, d_li_Ch,\n",
    "                                                                  consensus_edges_between_cj_ch_for_l,  is_weighted, weight)\n",
    "    #compute the addition update in modularity\n",
    "    addition_modularity_update = modularity_between_update(d_vl, d_int_lc, d_sq_l_c, d_li_Cj, d_li_Ch,\n",
    "                                                           e_prime, is_weighted, weight)\n",
    "    #compute both operations jointly: first add the new edges and compute the increase in modularity and then remove the old\n",
    "    # ones and compute the removal update on the new updated community\n",
    "    both_modularity_update = modularity_between_update_both(d_vl, d_int_lc, d_li_Cj, d_li_Ch, j, cj, consensus, d_lc_dict,\n",
    "                                                            layers, layer, consensus_edges_between_cj_ch_for_l, e_prime, is_weighted, weight)\n",
    "    best_update = max([removal_modularity_update, addition_modularity_update, both_modularity_update], key = lambda x: x[1])\n",
    "    consensus_copy = consensus.copy()\n",
    "    edges_between_cj_ch_l_copy = cj_neighbors[h][layer].copy()\n",
    "    if best_update[0] == 'r' and len(consensus_edges_between_cj_ch_for_l) > 0:\n",
    "        edges_between_cj_ch_l_copy = []\n",
    "        for edge in consensus_edges_between_cj_ch_for_l:\n",
    "            consensus_copy.remove_edge(edge[0], edge[1], edge[2])\n",
    "    elif best_update[0] == 'a':\n",
    "        edges_between_cj_ch_l_copy.extend(e_prime)\n",
    "        consensus_copy.add__edges_from(e_prime)\n",
    "    elif best_update[0] == 'b' and len(consensus_edges_between_cj_ch_for_l) > 0:\n",
    "        edges_between_cj_ch_l_copy = e_prime\n",
    "        for edge in consensus_edges_between_cj_ch_for_l:\n",
    "            consensus_copy.remove_edge(edge[0], edge[1], edge[2])\n",
    "        consensus_copy.add_weighted_edges_from(e_prime)\n",
    "    \n",
    "    return (consensus_copy, edges_between_cj_ch_l_copy, h, best_update[1])\n",
    "\n",
    "# ================================================================ #\n",
    "# C-EMCD ALGORITHM\n",
    "# ================================================================ #\n",
    "\n",
    "#compute single_linkage on coass_matrix -> cut on threshold -> compute nodes subgraphs (communities)\n",
    "def c_emcd(coass_matrix: np.ndarray, theta: float, G: nx.MultiDiGraph) -> List[nx.Graph]:\n",
    "    theta_dist = 1 - theta\n",
    "    consensus = []\n",
    "    agg = AgglomerativeClustering(n_clusters = None, metric = 'precomputed', linkage = 'single', distance_threshold = theta_dist)\n",
    "    communities = agg.fit_predict(coass_matrix)\n",
    "    communities_by_nodes = get_nodes_in_communities(communities, G)\n",
    "    for subset in communities_by_nodes:\n",
    "        consensus.append(G.subgraph(subset))\n",
    "    return consensus\n",
    "\n",
    "def cc_emcd_fast(G: nx.MultiGraph, base_cluster: List[nx.MultiGraph], theta: float) -> Union[List[nx.MultiGraph], dict, dict]:\n",
    "    theta_dist = 1 - theta\n",
    "    print('=====================================================================')\n",
    "    print('Computing co-association matrix, mij, inverse mij...')\n",
    "    coass_matrix, mij, inverse_mij = compute_coass_sparse_matrix(G, base_cluster, True, True, theta)\n",
    "    print('Done!')\n",
    "    print('=====================================================================')\n",
    "    print(f'Computing Consensus with respect to distance matrix, theta: {theta_dist}')\n",
    "    coms = c_emcd(coass_matrix.toarray(), theta_dist, G)\n",
    "    print('Done!')\n",
    "    print('=====================================================================')\n",
    "    print(f'Computing the intracommunity edges matrix...')\n",
    "    intracommunity_edges = get_intracommunity_edges_matrix_ccemcd(G, coms, mij)\n",
    "    print('Done!')\n",
    "    print('=====================================================================')\n",
    "    print('Computing the intercommunity edges matrix...')\n",
    "    intercommunity_edges = get_intercommunity_edges_ccemcd(G, inverse_mij, coms)\n",
    "    print('Done!')\n",
    "    return coms, intracommunity_edges, intercommunity_edges\n",
    "\n",
    "# ================================================================ #\n",
    "# M-EMCD ALGORITHM\n",
    "# ================================================================ #\n",
    "def m_emcd(G: nx.MultiDiGraph, coms: List[str], theta: float, max_iteration: int, threshold: float, weight: str = 'weight') -> List[nx.MultiDiGraph]:\n",
    "    #STARTUP PHASE\n",
    "    #compute coassociation matrix and lowerbound for the consensus using the cc-emcd\n",
    "    # print(\"Computing co-association matrix...\")\n",
    "    # mij, coass_matrix = compute_coass_matrix(G, coms)\n",
    "    print('Computing lower-bound consensus through CC-EMCD...')\n",
    "    cc_emcd_coms, intracomm_edges, intercomm_edges = cc_emcd_fast(G, coms, theta)\n",
    "    consensus_lower, consensus_comms = create_consensus_structure(G, intracomm_edges, intercomm_edges)\n",
    "    # print('initial consensus structure')\n",
    "    # for edge in consensus_lower.edges(keys = True):\n",
    "    #     print(edge)\n",
    "    consensus_star = consensus_lower\n",
    "    print(f'Consensus communities: {len(consensus_comms)}')\n",
    "    iteration = 0\n",
    "    delta_Q = np.inf\n",
    "    layers = G.graph['layers'].values()\n",
    "    #Compute initial degrees and modularity\n",
    "    print('Computing initial degrees and modularity...')\n",
    "    d_vl = D_VL_new(G)\n",
    "    #d_int_lc = D_int_lc(consensus_lower, layers)\n",
    "    d_int_lc = D_int_lc_new(consensus_comms)\n",
    "    #d_sq_l_c = D_sq_l_c(consensus_lower, layers)\n",
    "    d_lc_dict = compute_D_l_c_dict(consensus_star, consensus_comms, layers, weight)\n",
    "    d_sq_l_c = D_sq_l_c_new(d_lc_dict)\n",
    "    prev_Q = modularity(d_vl, d_int_lc, d_sq_l_c)\n",
    "    prev_prev_Q = prev_Q\n",
    "    print(f\"Initial modularity: {prev_Q:.4f}\")\n",
    "    while iteration < max_iteration:\n",
    "        print(f\"\\n--- Iteration {iteration} ---\")\n",
    "        iteration += 1\n",
    "        improved = False\n",
    "        #start the optimization loop\n",
    "        for value in layers:\n",
    "            print(f'Computing updates for layer {value}')\n",
    "            #compute the degrees and modularity\n",
    "            intracommunity_updates = []\n",
    "            comm_candidates = []\n",
    "            added_edges = []\n",
    "            #loop over every community in the current consensus\n",
    "            for j, cj in enumerate(consensus_comms):\n",
    "                print(f'Computing updates for community c{j}')\n",
    "                #print(cj)\n",
    "                d_li_cj = d_lc_dict[j][value]\n",
    "                com_candidate, Q_intracomm_update, new_edges = update_community(G, prev_Q, cj, value, d_vl, d_int_lc, d_sq_l_c, d_li_cj)\n",
    "                #cj_candidate = update_community(G, prev_Q, cj, value, d_vl, d_int_lc, d_sq_l_c, d_li_cj)\n",
    "                comm_candidates.append(com_candidate)\n",
    "                intracommunity_updates.append(Q_intracomm_update)\n",
    "                added_edges.append(new_edges)\n",
    "            #Select the best update\n",
    "            print(f'  Intra-community updates for layer {value}: {intracommunity_updates}')\n",
    "            j_star = np.argmax(intracommunity_updates)\n",
    "            best_intracomm_Q = intracommunity_updates[j_star]\n",
    "            if best_intracomm_Q > prev_Q:\n",
    "                improvement = best_intracomm_Q - prev_Q\n",
    "                print(f\"  Intra-community update: Community {j_star}, \"\n",
    "                      f\"ΔQ = +{improvement:.6f}\")\n",
    "                #update consensus\n",
    "                c_j_star = comm_candidates[j_star]\n",
    "                #consensus_star[j_star] = c_j_star\n",
    "                consensus_comms[j_star] = c_j_star\n",
    "                #consensus_star.add_edges_from([(e[0], e[1], e[2], e[3]) for e in added_edges[j_star]])\n",
    "                consensus_star.add_edges_from(added_edges[j_star])\n",
    "                #update modularity\n",
    "                prev_Q = best_intracomm_Q\n",
    "                improved = True\n",
    "                #startup of the second update  \n",
    "                #degree of the improved community \n",
    "                d_lc_dict[j_star] = compute_community_D_l_c(consensus_star, c_j_star, layers, weight)  \n",
    "                d_int_lc = D_int_lc_new(consensus_comms)  \n",
    "                d_sq_l_c = D_sq_l_c_new(d_lc_dict)         \n",
    "                d_li_cj_star = d_lc_dict[j_star][value]\n",
    "                #We updated C_j and thus can proceed in updating the community structure\n",
    "                print(f'Computing community structure updates for community at index {j_star}, at layer {value}')\n",
    "                cj_neighbors = intercomm_edges[j_star]\n",
    "                intercomm_candidates = []\n",
    "                best_intercomm_Q = -np.inf\n",
    "                for h in cj_neighbors.keys():\n",
    "                    if h == j_star:\n",
    "                        continue\n",
    "                    if len(cj_neighbors[h][value]) > 0:\n",
    "                        ch = consensus_comms[h]\n",
    "                        d_li_ch = d_lc_dict[h][value]\n",
    "                        ch_candidate = update_community_structure(G, consensus_star, c_j_star, ch, h, j_star, cj_neighbors, layers, value,\n",
    "                                                                        d_vl, d_int_lc, d_sq_l_c, d_li_cj_star, d_li_ch, d_lc_dict, True, weight)\n",
    "                        #save also the original community index so the intercommunity edges matrix can be updated\n",
    "                        intercomm_candidates.append(ch_candidate)\n",
    "                #select the best update\n",
    "                if len(intercomm_candidates) > 0:\n",
    "                    best_intercomm_update = max(intercomm_candidates, key = lambda x: x[3])\n",
    "                    best_intercomm_Q = best_intercomm_update[3]\n",
    "                #if we are incrementing wrt the previous update (cj*)\n",
    "                if best_intercomm_Q > prev_Q:\n",
    "                    #print('entro mai qua?')\n",
    "                    #update the intercomm_edges matrix\n",
    "                    h_star = best_intercomm_update[2]\n",
    "                    edges_update = best_intercomm_update[1]\n",
    "                    print(edges_update)\n",
    "                    print(len(best_intercomm_update[0].edges()))\n",
    "                    cj_neighbors[h_star][value] = edges_update\n",
    "                    #update consensus structure\n",
    "                    consensus_star = best_intercomm_update[0]\n",
    "                    #update d_li_cj_star\n",
    "                    d_lc_dict[j_star] = compute_community_D_l_c(consensus_star, c_j_star, layers, weight) \n",
    "                    improvement = best_intercomm_Q - prev_Q\n",
    "                    prev_prev_Q = prev_Q\n",
    "                    prev_Q = best_intercomm_Q\n",
    "                    #current_Q = \n",
    "                    improved = True\n",
    "                    print(f\"Inter-community update for layer {value}: ΔQ = +{improvement:.6f}\")\n",
    "\n",
    "        # Recompute statistics after community update\n",
    "        # d_int_lc = D_int_lc(consensus_star, layers)\n",
    "        # d_sq_l_c = D_sq_l_c(consensus_star, layers)\n",
    "        d_int_lc = D_int_lc_new(consensus_comms)\n",
    "        d_sq_l_c = D_sq_l_c_new(d_lc_dict)\n",
    "        #current_Q = modularity(d_vl, d_int_lc, d_sq_l_c)\n",
    "        delta_Q = abs(prev_Q - prev_prev_Q)\n",
    "    \n",
    "        print(f\"End of iteration {iteration}: Q = {prev_Q:.4f}, ΔQ = {delta_Q:.6f}\")\n",
    "        \n",
    "        if not improved or delta_Q < threshold:\n",
    "            print(f\"\\nConverged after {iteration} iterations\")\n",
    "            break\n",
    "        #prev_Q = current_Q\n",
    "\n",
    "    #final_Q = modularity(d_vl, d_int_lc, d_sq_l_c)\n",
    "    print(f\"\\nFinal modularity: {prev_Q:.4f}\")\n",
    "    #print(f\"Number of communities: {len()}\")\n",
    "    \n",
    "    return consensus_star, consensus_comms, prev_Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed8d38d",
   "metadata": {},
   "source": [
    "<H2> USAGE EXAMPLE </H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64658a65",
   "metadata": {},
   "source": [
    "The create_tagarelli_network() method provides a small example taken from the paper Ensemble-based Community Detection In Multilayer Networks by Tagarelli et al., in which the algorithm has been first presented (https://doi.org/10.1007/s10618-017-0528-8), in particular the network proposed in figure 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa2ff2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagarelli_graph, tagarelli_clustering = create_tagarelli_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbbacd6",
   "metadata": {},
   "source": [
    "The create_multiplex_from_graphs converts a list of single layer graphs to a networkx multiGraph. We also need to pass the name of the layers so that these can be encoded in the graph structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "95488739",
   "metadata": {},
   "outputs": [],
   "source": [
    "mg_tagarelli = create_multiplex_from_graphs(tagarelli_graph, ['L1', 'L2', 'L3'], False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271150d9",
   "metadata": {},
   "source": [
    "The M-EMCD algorithm can be executed by simply callind the m_emcd function: the needed parameters are a multilayer graph, the initial clustering (obtained via single layer community detection), the theta parameter, the max number of iterations and convergence threshold, and a string indicating the name of the attribute that contains the weight of the edges in the graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92b736a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing lower-bound consensus through CC-EMCD...\n",
      "=====================================================================\n",
      "Computing co-association matrix, mij, inverse mij...\n",
      "Done!\n",
      "=====================================================================\n",
      "Computing Consensus with respect to distance matrix, theta: 0.4\n",
      "Done!\n",
      "=====================================================================\n",
      "Computing the intracommunity edges matrix...\n",
      "Done!\n",
      "=====================================================================\n",
      "Computing the intercommunity edges matrix...\n",
      "Done!\n",
      "Consensus communities: 4\n",
      "Computing initial degrees and modularity...\n",
      "Initial modularity: 0.5010\n",
      "\n",
      "--- Iteration 0 ---\n",
      "Computing updates for layer L1\n",
      "Computing updates for community c0\n",
      "Computing updates for community c1\n",
      "Computing updates for community c2\n",
      "Computing updates for community c3\n",
      "  Intra-community updates for layer L1: [np.float64(0.5010405827263267), np.float64(0.5010405827263267), np.float64(0.5010405827263267), np.float64(0.5010405827263267)]\n",
      "Computing updates for layer L2\n",
      "Computing updates for community c0\n",
      "Computing updates for community c1\n",
      "Computing updates for community c2\n",
      "Computing updates for community c3\n",
      "  Intra-community updates for layer L2: [np.float64(0.5010405827263267), np.float64(0.51318359375), np.float64(0.5010405827263267), np.float64(0.5010405827263267)]\n",
      "  Intra-community update: Community 1, ΔQ = +0.012143\n",
      "Computing community structure updates for community at index 1, at layer L2\n",
      "[]\n",
      "23\n",
      "Inter-community update for layer L2: ΔQ = +0.000150\n",
      "Computing updates for layer L3\n",
      "Computing updates for community c0\n",
      "Computing updates for community c1\n",
      "Computing updates for community c2\n",
      "Computing updates for community c3\n",
      "  Intra-community updates for layer L3: [np.float64(0.5133333333333333), np.float64(0.5133333333333333), np.float64(0.5133333333333333), np.float64(0.5133333333333333)]\n",
      "End of iteration 1: Q = 0.5133, ΔQ = 0.000150\n",
      "\n",
      "--- Iteration 1 ---\n",
      "Computing updates for layer L1\n",
      "Computing updates for community c0\n",
      "Computing updates for community c1\n",
      "Computing updates for community c2\n",
      "Computing updates for community c3\n",
      "  Intra-community updates for layer L1: [np.float64(0.5133333333333333), np.float64(0.5133333333333333), np.float64(0.5133333333333333), np.float64(0.5133333333333333)]\n",
      "Computing updates for layer L2\n",
      "Computing updates for community c0\n",
      "Computing updates for community c1\n",
      "Computing updates for community c2\n",
      "Computing updates for community c3\n",
      "  Intra-community updates for layer L2: [np.float64(0.5133333333333333), np.float64(0.509521484375), np.float64(0.5133333333333333), np.float64(0.5133333333333333)]\n",
      "Computing updates for layer L3\n",
      "Computing updates for community c0\n",
      "Computing updates for community c1\n",
      "Computing updates for community c2\n",
      "Computing updates for community c3\n",
      "  Intra-community updates for layer L3: [np.float64(0.5133333333333333), np.float64(0.5133333333333333), np.float64(0.5133333333333333), np.float64(0.5133333333333333)]\n",
      "End of iteration 2: Q = 0.5133, ΔQ = 0.000150\n",
      "\n",
      "Converged after 2 iterations\n",
      "\n",
      "Final modularity: 0.5133\n"
     ]
    }
   ],
   "source": [
    "tagarelli_memcd_consensus ,tagarelli_memcd_coms, tagarelli_memcd_modularity = m_emcd(mg_tagarelli, tagarelli_clustering, 0.6, 100, 0.0000001, 'weight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphAnalysis",
   "language": "python",
   "name": "graphanalysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
